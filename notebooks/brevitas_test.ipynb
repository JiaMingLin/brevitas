{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.inject.enum import *\n",
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.restrict_val import FloatToIntImplType\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "from brevitas.core.zero_point import ZeroZeroPoint\n",
    "from brevitas.quant.solver import WeightQuantSolver, ActQuantSolver\n",
    "from brevitas.quant.base import *\n",
    "from brevitas.core.function_wrapper.ops_ste import CeilSte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Int8WeightPerTensorFloatScratch(WeightQuantSolver):\n",
    "    quant_type = QuantType.INT # integer quantization\n",
    "    bit_width_impl_type = BitWidthImplType.CONST # constant bit width\n",
    "    float_to_int_impl_type = FloatToIntImplType.ROUND # round to nearest\n",
    "    scaling_impl_type = ScalingImplType.STATS # scale based on statistics\n",
    "    scaling_stats_op = StatsOp.MAX # scale statistics is the absmax value\n",
    "    restrict_scaling_type = RestrictValueType.FP # scale factor is a floating point value\n",
    "    scaling_per_output_channel = False # scale is per tensor\n",
    "    bit_width = 8 # bit width is 8\n",
    "    signed = True # quantization range is signed\n",
    "    narrow_range = True # quantization range is [-127,127] rather than [-128, 127]\n",
    "    zero_point_impl = ZeroZeroPoint # zero point is 0.\n",
    "    \n",
    "class Int8ActPerTensorFloatScratch(ActQuantSolver):\n",
    "    quant_type = QuantType.INT # integer quantization\n",
    "    bit_width_impl_type = BitWidthImplType.CONST # constant bit width\n",
    "    float_to_int_impl_type = FloatToIntImplType.ROUND # round to nearest\n",
    "    scaling_impl_type = ScalingImplType.PARAMETER_FROM_STATS # scale is a parameter initialized from statistics\n",
    "    scaling_stats_op = StatsOp.PERCENTILE # scale statistics is a percentile of the abs value\n",
    "    high_percentile_q = 99.999 # percentile is 99.999\n",
    "    collect_stats_steps = 300  # statistics are collected for 300 forward steps before switching to a learned parameter\n",
    "    restrict_scaling_type = RestrictValueType.FP # scale is a floating-point value\n",
    "    scaling_per_output_channel = False  # scale is per tensor\n",
    "    bit_width = 8  # bit width is 8\n",
    "    signed = True # quantization range is signed\n",
    "    narrow_range = False # quantization range is [-128, 127] rather than [-127, 127]\n",
    "    zero_point_impl = ZeroZeroPoint # zero point is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantIdentity(\n",
      "  (input_quant): ActQuantProxyFromInjector(\n",
      "    (_zero_hw_sentinel): StatelessBuffer()\n",
      "  )\n",
      "  (act_quant): ActQuantProxyFromInjector(\n",
      "    (_zero_hw_sentinel): StatelessBuffer()\n",
      "    (fused_activation_quant_proxy): FusedActivationQuantProxy(\n",
      "      (activation_impl): Identity()\n",
      "      (tensor_quant): RescalingIntQuant(\n",
      "        (int_quant): IntQuant(\n",
      "          (float_to_int_impl): RoundSte()\n",
      "          (tensor_clamp_impl): TensorClamp()\n",
      "          (delay_wrapper): DelayWrapper(\n",
      "            (delay_impl): _NoDelay()\n",
      "          )\n",
      "        )\n",
      "        (scaling_impl): ParameterFromRuntimeStatsScaling(\n",
      "          (stats_input_view_shape_impl): OverTensorView()\n",
      "          (stats): _Stats(\n",
      "            (stats_impl): AbsPercentile()\n",
      "          )\n",
      "          (restrict_scaling): _RestrictValue(\n",
      "            (restrict_value_impl): FloatRestrictValue()\n",
      "          )\n",
      "          (clamp_scaling): _ClampValue(\n",
      "            (clamp_min_ste): Identity()\n",
      "          )\n",
      "          (restrict_inplace_preprocess): Identity()\n",
      "          (restrict_preprocess): Identity()\n",
      "        )\n",
      "        (int_scaling_impl): IntScaling()\n",
      "        (zero_point_impl): ZeroZeroPoint(\n",
      "          (zero_point): StatelessBuffer()\n",
      "        )\n",
      "        (msb_clamp_bit_width_impl): BitWidthConst(\n",
      "          (bit_width): StatelessBuffer()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from brevitas.nn import QuantLinear, QuantIdentity\n",
    "quant_linear = QuantLinear(2, 4, weight_quant=Int8WeightPerTensorFloatScratch ,bias=True)\n",
    "quant_identity = QuantIdentity(act_quant = Int8ActPerTensorFloatScratch, return_quant_tensor=True)\n",
    "print(quant_identity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:  tensor([[0.1168, 0.4111, 0.9212, 0.8079, 0.9039]])\n",
      "Weight Quant:  QuantTensor(value=tensor([[0.1155, 0.4095, 0.6667, 0.6667, 0.6667]], grad_fn=<MulBackward0>), scale=tensor(0.0052, grad_fn=<DivBackward0>), zero_point=tensor(0.), bit_width=tensor(8.), signed_t=tensor(True), training_t=tensor(True))\n",
      "Tensor Quant:  (tensor([[0.1155, 0.4095, 0.6667, 0.6667, 0.6667]], grad_fn=<MulBackward0>), tensor(0.0052, grad_fn=<DivBackward0>), tensor(0.), tensor(8.))\n",
      "Scaling:  tensor(0.6667, grad_fn=<ViewBackward0>)\n",
      "Int Scaling:  tensor([[-0.4578, -0.3352, -0.0532, -0.1247, -0.0644]])\n",
      "Scale Factor:  tensor([[ -1.4562,  -1.9892, -12.5399,  -5.3476, -10.3496]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch random array\n",
    "arr = torch.rand(1,5)\n",
    "weight_quant = quant_linear.weight_quant\n",
    "tensor_quant = weight_quant.tensor_quant # instance RescalingIntQuant\n",
    "scaling_impl = quant_linear.weight_quant.tensor_quant.scaling_impl # threshold, StatsFromParameterScaling\n",
    "int_scaling_impl = quant_linear.weight_quant.tensor_quant.int_scaling_impl # int threshold\n",
    "\n",
    "first_tracked_param = scaling_impl.parameter_list_stats.first_tracked_param\n",
    "\n",
    "# random torch tensor\n",
    "\n",
    "print(\"Original tensor: \", arr)\n",
    "print(\"Weight Quant: \", weight_quant(arr))\n",
    "print(\"Tensor Quant: \", tensor_quant(arr))\n",
    "threshold = scaling_impl(arr)\n",
    "print(\"Scaling: \", threshold)\n",
    "int_threshold = int_scaling_impl(arr)\n",
    "print(\"Int Scaling: \", int_scaling_impl(arr))\n",
    "print(\"Scale Factor: \", threshold/int_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_tracked_param:  tensor([ 0.4354,  0.3994,  0.1296, -0.1740,  0.5606,  0.6667, -0.6104, -0.1527],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "quant_linear\n",
    "print(\"first_tracked_param: \", first_tracked_param())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.4354,  0.3994],\n",
       "         [ 0.1296, -0.1740],\n",
       "         [ 0.5606,  0.6667],\n",
       "         [-0.6104, -0.1527]], requires_grad=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaling_impl.tracked_parameter_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantIdentity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0574, 0.4205, 0.8934, 0.9537],\n",
      "        [0.2962, 0.5842, 0.3586, 0.7235],\n",
      "        [0.0826, 0.7101, 0.4055, 0.6815],\n",
      "        [0.7516, 0.0194, 0.9429, 0.2446]])\n",
      "QuantTensor(value=tensor([[0.0596, 0.4172, 0.8940, 0.9462],\n",
      "        [0.2980, 0.5811, 0.3576, 0.7227],\n",
      "        [0.0820, 0.7078, 0.4023, 0.6780],\n",
      "        [0.7525, 0.0224, 0.9462, 0.2459]], grad_fn=<MulBackward0>), scale=tensor(0.0075, grad_fn=<DivBackward0>), zero_point=tensor(0.), bit_width=tensor(8.), signed_t=tensor(True), training_t=tensor(True))\n"
     ]
    }
   ],
   "source": [
    "input_arr = torch.rand(4,4)\n",
    "print(input_arr)\n",
    "print(quant_identity(input_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n",
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "from brevitas.core.scaling.standalone import ConstScaling \n",
    "\n",
    "from brevitas.core.restrict_val import PowerOfTwoRestrictValue\n",
    "int_scaling_impl = ConstScaling(3.0)\n",
    "pot_scaling_impl = ConstScaling(0.5, restrict_scaling_impl=PowerOfTwoRestrictValue())\n",
    "print(pot_scaling_impl(torch.empty(1)))\n",
    "print(int_scaling_impl(torch.empty(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1.5850, 1.5850, 1.5850, 1.5850, 1.5850])\n",
      "tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "from brevitas.core.restrict_val import PowerOfTwoRestrictValue\n",
    "import torch\n",
    "arr = torch.ones(5)\n",
    "restrict_scaling_impl = PowerOfTwoRestrictValue()\n",
    "print(restrict_scaling_impl.restrict_init_tensor(arr))\n",
    "print(restrict_scaling_impl.restrict_init_tensor(arr*2))\n",
    "\n",
    "print(restrict_scaling_impl.restrict_init_tensor(arr*3))\n",
    "\n",
    "print(restrict_scaling_impl.restrict_init_tensor(arr*4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantIdentity Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyError",
     "evalue": "'Int8ActPerTensorFloatInference' can not resolve attribute 'max_val' while building 'scaling_init_impl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDependencyError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     narrow_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# quantization range is [-128, 127] rather than [-127, 127]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     zero_point_impl \u001b[38;5;241m=\u001b[39m ZeroZeroPoint \u001b[38;5;66;03m# zero point is 0.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m quant_identity_inference \u001b[38;5;241m=\u001b[39m \u001b[43mQuantIdentity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mact_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mInt8ActPerTensorFloatInference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_quant_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/brevitas/nn/quant_activation.py:113\u001b[0m, in \u001b[0;36mQuantIdentity.__init__\u001b[0;34m(self, act_quant, return_quant_tensor, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    110\u001b[0m         act_quant: Optional[ActQuantType] \u001b[38;5;241m=\u001b[39m Int8ActPerTensorFloat,\n\u001b[1;32m    111\u001b[0m         return_quant_tensor: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 113\u001b[0m     \u001b[43mQuantNLAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mact_impl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpassthrough_act\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mact_quant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mact_quant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_quant_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_quant_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/brevitas/nn/quant_layer.py:36\u001b[0m, in \u001b[0;36mQuantNonLinearActLayer.__init__\u001b[0;34m(self, act_impl, passthrough_act, input_quant, act_quant, return_quant_tensor, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m QuantLayerMixin\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, return_quant_tensor)\n\u001b[1;32m     35\u001b[0m QuantInputMixin\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_quant, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mQuantNonLinearActMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassthrough_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_quant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/brevitas/nn/mixin/act.py:118\u001b[0m, in \u001b[0;36mQuantNonLinearActMixin.__init__\u001b[0;34m(self, act_impl, passthrough_act, act_quant, act_proxy_prefix, act_kwargs_prefix, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    109\u001b[0m         act_impl: Optional[Type[Module]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m         act_kwargs_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     prefixed_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    116\u001b[0m         act_kwargs_prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mact_impl\u001b[39m\u001b[38;5;124m'\u001b[39m: act_impl,\n\u001b[1;32m    117\u001b[0m         act_kwargs_prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough_act\u001b[39m\u001b[38;5;124m'\u001b[39m: passthrough_act}\n\u001b[0;32m--> 118\u001b[0m     \u001b[43mQuantProxyMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mact_quant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxy_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mact_proxy_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mact_kwargs_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxy_protocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mActQuantProxyProtocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnone_quant_injector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNoneActQuant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprefixed_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/brevitas/nn/mixin/base.py:70\u001b[0m, in \u001b[0;36mQuantProxyMixin.__init__\u001b[0;34m(self, quant, proxy_protocol, none_quant_injector, proxy_prefix, kwargs_prefix, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     quant_injector \u001b[38;5;241m=\u001b[39m quant\n\u001b[1;32m     69\u001b[0m     quant_injector \u001b[38;5;241m=\u001b[39m quant_injector\u001b[38;5;241m.\u001b[39mlet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfilter_kwargs(kwargs_prefix, kwargs))\n\u001b[0;32m---> 70\u001b[0m     quant \u001b[38;5;241m=\u001b[39m \u001b[43mquant_injector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_injector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(quant, proxy_protocol):\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/brevitas/proxy/runtime_quant.py:89\u001b[0m, in \u001b[0;36mActQuantProxyFromInjector.__init__\u001b[0;34m(self, quant_layer, quant_injector)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, quant_layer, quant_injector):\n\u001b[0;32m---> 89\u001b[0m     \u001b[43mQuantProxyFromInjector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_injector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     ActQuantProxyProtocol\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_passthrough_act \u001b[38;5;241m=\u001b[39m _is_passthrough_act(quant_injector)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/brevitas/proxy/quant_proxy.py:89\u001b[0m, in \u001b[0;36mQuantProxyFromInjector.__init__\u001b[0;34m(self, quant_layer, quant_injector)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Use a normal list and not a ModuleList since this is a pointer to parent modules\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracked_module_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_tracked_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquant_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_quant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/brevitas/proxy/quant_proxy.py:131\u001b[0m, in \u001b[0;36mQuantProxyFromInjector.add_tracked_module\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracked_module_list\u001b[38;5;241m.\u001b[39mappend(module)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_tracked_modules()\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_tensor_quant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to add None as a parent module.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/brevitas/proxy/runtime_quant.py:102\u001b[0m, in \u001b[0;36mActQuantProxyFromInjector.init_tensor_quant\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_tensor_quant\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 102\u001b[0m     tensor_quant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_injector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_quant\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mact_impl\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_injector:\n\u001b[1;32m    104\u001b[0m         act_impl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_injector\u001b[38;5;241m.\u001b[39mact_impl\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/brevitas/inject/__init__.py:129\u001b[0m, in \u001b[0;36m_ExtendedInjectorType.__getattr__\u001b[0;34m(cls, attrname)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m can not resolve attribute \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, current_attr)\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DependencyError(message)\n\u001b[1;32m    131\u001b[0m marker, attribute, args, have_defaults \u001b[38;5;241m=\u001b[39m spec\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(args)\u001b[38;5;241m.\u001b[39missubset(cached):\n",
      "\u001b[0;31mDependencyError\u001b[0m: 'Int8ActPerTensorFloatInference' can not resolve attribute 'max_val' while building 'scaling_init_impl'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Int8ActPerTensorFloatInference(ActQuantSolver):\n",
    "    quant_type = QuantType.INT # integer quantization\n",
    "    bit_width_impl_type = BitWidthImplType.CONST # constant bit width\n",
    "    float_to_int_impl_type = FloatToIntImplType.ROUND # round to nearest\n",
    "    scaling_impl_type = ScalingImplType.PARAMETER_FROM_STATS # scale is a parameter initialized from statistics\n",
    "    scaling_stats_op = StatsOp.PERCENTILE # scale statistics is a percentile of the abs value\n",
    "    high_percentile_q = 99.999 # percentile is 99.999\n",
    "    collect_stats_steps = 300  # statistics are collected for 300 forward steps before switching to a learned parameter\n",
    "    restrict_scaling_type = RestrictValueType.FP # scale is a floating-point value\n",
    "    scaling_per_output_channel = False  # scale is per tensor\n",
    "    bit_width = 8  # bit width is 8\n",
    "    signed = True # quantization range is signed\n",
    "    narrow_range = False # quantization range is [-128, 127] rather than [-127, 127]\n",
    "    zero_point_impl = ZeroZeroPoint # zero point is 0.\n",
    "\n",
    "quant_identity_inference = QuantIdentity(act_quant=Int8ActPerTensorFloatInference, return_quant_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = torch.rand()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
